# FrogStatus Configuration

# API Server
PORT=4000

# Build Metadata
BUILD_NAME=frogstatus
BUILD_NUMBER=1
GIT_COMMIT=LOCAL_DEV
ENVIRONMENT=dev
XRAY_STATUS=UNKNOWN

# ====================================
# Chatbot LLM Configuration
# ====================================

# OpenAI Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4-turbo-preview

# Anthropic Claude Configuration
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Google Gemini Configuration
# Get your API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=
GEMINI_MODEL=gemini-pro

# ====================================
# JFrog MCP Server Configuration
# ====================================

# MCP server integration is included for Shadow AI detection demo purposes
# The @modelcontextprotocol/sdk dependency in package.json will be detected by JFrog Xray
#
# Note: Full MCP integration requires OIDC authentication which is beyond the scope
# of this demo. The chatbot works fully without MCP - it demonstrates AI usage through:
# 1. LLM SDK dependencies (OpenAI, Anthropic, Gemini)
# 2. Transformers.js with local models
# 3. MCP SDK package presence
#
# Set to true to see MCP in the UI (non-functional, for demo purposes only)
MCP_SERVER_ENABLED=false

# ====================================
# Notes
# ====================================
#
# - The local Transformers.js model works without any API keys
# - To enable cloud providers, add at least one API key above
# - JFrog MCP server integration is optional
# - DO NOT commit this file with actual API keys to version control
# - Copy this file to .env and fill in your values
